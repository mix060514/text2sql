
services:
  webui:
    build: .
    restart: always
    ports:
      - "8501:8501"
    volumes:
      - .:/app
      - /app/.venv
    environment:
      - WATCH_FILES=true
      - LLAMA_CPP_API_BASE=http://llama-cpp:8080
    networks:
      - default
      - ai-stack_default

networks:
  ai-stack_default:
    external: true
